Differential Privacy

	different from k-anonymity and l-diversity
	
	Privatised Analysis on original data to produce results released to public
	
	Promise of Differential Privacy
		>>>Attack should not be able to tell if user is in or not in server
		
		R = private results releasing
		
		P(user in dataset) ~ P(user not in dataset) = R
	
		Attacker can still learn category/range of attribute about user
			Make guess of probability using database of other users
			
		>>>Only prevent attackers from knowing if specific individual is in dataset
		
	Global sensitivity
		maximum difference in queries (functions) that adding/removing individuals can cause
		
		Range of maximum effect on data
		Consider worst case scenario
		
		
	Privacy Budget
		e = privacy budget that should be in used
		
		closeness of the two probabilities
			difference of the effect of user being in or not the dataset
			
		e of 0 imply maximum privacy and no utility
		